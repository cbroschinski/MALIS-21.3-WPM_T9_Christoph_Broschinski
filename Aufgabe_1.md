# Beschreibung von datenintensiven und datenfokusierten Aktivitäten im eigenen Arbeitsalltag

In meinem Arbeitsalltag bin ich vor allem für das [OpenAPC-Projekt](https://github.com/OpenAPC/openapc-de) tätig, das Daten zum kostenpflichtigen Open Access-Publizieren sammelt, aufbereitet und veröffentlicht. Das gesamte Projekt ist dabei naturgemäß enorm datenintensiv: Die von unseren Teilnehmern bereitgestellten Beiträge (alle Einreichungen zu OpenAPC geschehen auf freiwilliger Basis) müssen entgegengenommen, formatiert, angereichert, überprüft und dann strukturiert in unserem Repository abgelegt werden. Im Folgenden soll dieser Workflow näher erläutert werden.

## Datenverarbeitung in OpenAPC

Teilnehmende Einrichtungen (dabei kann es sich um einzelne Hochschulen und Forschungsinstitute oder auch zentrale Einrichtungen wie Nationalbibliotheken handeln) können neue Daten entweder per Mail oder direkt als [Pull Request](https://github.com/OpenAPC/openapc-de/pulls) einreichen. [Diese Datei](https://raw.githubusercontent.com/OpenAPC/openapc-de/master/data/unileipzig/OpenAPC_LeipzigU_Gold_2020.csv) zeigt beispielsweise einen Beitrag der Universität Leipzig mit gezahlten APCs für das Jahr 2020.
Die Tabelle enthält dabei lediglich 5 Spalten (Pflichtfelder), das Zielformat unseren Datensatzes für Zeitschriftenartikel besteht allerdings aus [18 Spalten](https://github.com/OpenAPC/openapc-de/wiki/schema#mandatory-and-backup-columns). Die fehlenden Daten reichern wir automatisch aus mehreren externen Quellen an: So beziehen wir den Titel und Verlag der Zeitschrift beispielsweise aus [Crossref](https://www.crossref.org/) - wichtig, um konsistente Ansetzungen zu erzeugen. Weitere Provider für Metadaten, die wir verwenden, sind Pubmed Central, das DOAJ, das Web of Science sowie die ISSN-Organisation. Seit einiger Zeit werden außerdem Kostendaten für Open Access-Bücher gesammelt, hier kommt als Datenquelle noch das DOAB (Directory of Open Access Books) hinzu.
Die Anreicherung geschieht dabei im Wesentlichen automatisch: Ein [Python-Skript](https://github.com/OpenAPC/openapc-de/blob/master/python/apc_csv_processing.py) wird aus der Shell aufgerufen und enthält den Pfad zur Ausgangsdatei als Argument. Die CSV-Tabelle wird dann zeilenweise durchlaufen und verarbeitet, zum Schluss wird eine angereicherte Variante generiert, die üblicherweise durch das Suffix `_enriched` im Dateinamen gekennzeichnet wird - [hier](https://github.com/OpenAPC/openapc-de/blob/master/data/unileipzig/OpenAPC_LeipzigU_Gold_2020_enriched.csv) etwa das angereicherte Äquivalent zur oben erwähnten Beispieldatei aus Leipzig. Alle angereicherten Dateien zusammen bilden schließlich den OpenAPC-Datensatz [für Zeitschriftenartikel](https://github.com/OpenAPC/openapc-de/blob/master/data/apc_de.csv) bzw. denjenigen für [OA-Bücher](https://github.com/OpenAPC/openapc-de/blob/master/data/bpc.csv). Die folgende Grafik zeigt den Vorgang als Ablaufdiagramm:

![](https://www.ub.uni-bielefeld.de/~cbroschinski/presentations/slidy/graphics/openapc_enrichment_overview_v2.svg)

Das Anreicherungsskript ist dabei im Laufe der Jahre immer wieder verbessert und erweitert worden, um weitere Randfälle und Probleme, die während einer Datenanreicherung vorkommen können, möglichst automatisch beheben zu können.


