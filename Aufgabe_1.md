# Beschreibung von datenintensiven und datenfokussierten Aktivitäten im eigenen Arbeitsalltag

In meinem Arbeitsalltag bin ich vor allem für das [OpenAPC-Projekt](https://github.com/OpenAPC/openapc-de) tätig, das Daten zum kostenpflichtigen Open Access-Publizieren sammelt, aufbereitet und veröffentlicht[^1]. Das gesamte Projekt ist dabei naturgemäß enorm datenintensiv: Die von unseren Teilnehmern und Teilnehmerinnen bereitgestellten Beiträge (alle Einreichungen zu OpenAPC geschehen auf freiwilliger Basis) müssen entgegengenommen, formatiert, angereichert, überprüft und dann strukturiert in unserem Repository abgelegt werden. Im Folgenden soll dieser Workflow näher erläutert werden.

## Datenverarbeitung in OpenAPC

Teilnehmende Einrichtungen (dabei kann es sich um einzelne Hochschulen und Forschungsinstitute oder auch zentrale Einrichtungen wie Nationalbibliotheken handeln) können neue Daten entweder per Mail oder direkt als [Pull Request](https://github.com/OpenAPC/openapc-de/pulls) einreichen. [Diese Datei](https://raw.githubusercontent.com/OpenAPC/openapc-de/master/data/unileipzig/OpenAPC_LeipzigU_Gold_2020.csv) zeigt beispielsweise einen Beitrag der Universität Leipzig mit gezahlten APCs (Article Processing Charges) für das Jahr 2020.
Die Tabelle enthält dabei lediglich 5 Spalten (Pflichtfelder), das Zielformat unseres Datensatzes für Zeitschriftenartikel besteht allerdings aus [18 Spalten](https://github.com/OpenAPC/openapc-de/wiki/schema#mandatory-and-backup-columns). Die fehlenden Daten reichern wir automatisch aus mehreren externen Quellen an: So beziehen wir den Titel und Verlag der Zeitschrift beispielsweise aus [Crossref](https://www.crossref.org/) - wichtig, um konsistente Ansetzungen zu erzeugen. Weitere Provider für Metadaten, die wir verwenden, sind Pubmed Central, das [DOAJ](https://doaj.org/) (Directory of Open Access Journals), das Web of Science sowie die ISSN-Organisation. Seit einiger Zeit werden außerdem Kostendaten für Open Access-Bücher gesammelt, hier kommt als Datenquelle noch das DOAB (Directory of Open Access Books) hinzu.
Die Anreicherung geschieht dabei im Wesentlichen automatisch: Ein [Python-Skript](https://github.com/OpenAPC/openapc-de/blob/master/python/apc_csv_processing.py) wird aus der Shell aufgerufen und enthält den Pfad zur Ausgangsdatei als Argument. Die CSV-Tabelle wird dann zeilenweise durchlaufen und verarbeitet, zum Schluss wird eine angereicherte Variante generiert, die üblicherweise durch das Suffix `_enriched` im Dateinamen gekennzeichnet wird - [hier](https://github.com/OpenAPC/openapc-de/blob/master/data/unileipzig/OpenAPC_LeipzigU_Gold_2020_enriched.csv) etwa das angereicherte Äquivalent zur oben erwähnten Beispieldatei aus Leipzig. Alle angereicherten Dateien zusammen bilden schließlich den OpenAPC-Datensatz [für Zeitschriftenartikel](https://github.com/OpenAPC/openapc-de/blob/master/data/apc_de.csv) bzw. denjenigen für [OA-Bücher](https://github.com/OpenAPC/openapc-de/blob/master/data/bpc.csv). Die folgende Grafik zeigt den Vorgang als Ablaufdiagramm:

![](https://www.ub.uni-bielefeld.de/~cbroschinski/presentations/slidy/graphics/openapc_enrichment_overview_v2.svg)

Das Anreicherungsskript ist dabei im Laufe der Jahre immer wieder verbessert und erweitert worden, um weitere Randfälle und Probleme, die während einer Datenanreicherung vorkommen können, möglichst automatisch beheben zu können. Viele Funktionen sind dabei in ein eigenes Modul [ausgelagert](https://github.com/OpenAPC/openapc-de/blob/master/python/openapc_toolkit.py), teilweise werden diese durch andere Skripte genutzt, die ebenfalls im [python](https://github.com/OpenAPC/openapc-de/tree/master/python)-Verzeichnis zu finden sind. Eine komplette Beschreibung dieser Softwarelandschaft würde hier sicherlich den Rahmen sprengen, daher sollen hier nur einige interessante Fälle exemplarisch aufgelistet werden:

### Automatisches Zuordnen von Tabellenspalten

Gemäß unserer Vorgaben sollten eingereichte Tabellen ein bestimmtes wohldefiniertes Format haben. Die oben verlinkte [Beispieldatei](https://raw.githubusercontent.com/OpenAPC/openapc-de/master/data/unileipzig/OpenAPC_LeipzigU_Gold_2020.csv) aus Leipzig erfüllt diese Anforderungen: Es gibt die 5 Pflichtspalten `institution`, `period`, `euro`, `doi` und `is_hybrid`. Das ist allerdings in der Praxis längst nicht immer der Fall: Viele eingereichte Tabellen enthalten andere Spaltennamen, die Reihenfolge ist vertauscht oder es gibt zusätzliche Spalten mit Daten, die für OpenAPC nicht relevant sind. Um eine zeitaufwändige Vorverarbeitung zu vermeiden, kann das Anreicherungsskript solche Inkonsistenzen selbst auflösen: Spaltennamen können zunächst automatisiert über eine [Lookup-Tabelle](https://github.com/OpenAPC/openapc-de/blob/master/python/mappings.py#L407) bzw. Whitelist zugeordnet werden. Falls das scheitert, beherrscht das Skript auch eine heuristische Analyse: Der Inhalt einiger Felder einer unbekannten Spalte wird analysiert, um den Inhaltstyp zu bestimmen, was beispielsweise für Jahreszahlen, Euro-Beträge und DOIs (Digital Object Identifier) gut funktioniert. In letzter Instanz ist immer noch möglich, fehlende Spalteninformationen als Aufrufparameter zuzuweisen: `python apc_csv_processing.py dateiname.csv -euro 2` übergibt dem Skript beispielsweise die Information, dass es sich bei der 2. Spalte von links (ab 0 gezählt) um die `euro`-Spalte handelt.

### Normalisierung während der Anreicherung

Viele Metadaten, die entweder schon in den eingereichten Tabellen enthalten sind oder während der Anreicherung hinzugefügt werden, sind nicht normiert und müssen vereinheitlicht werden, um Inkonsistenzen im OpenAPC-Datensatz zu vermeiden. Auch dieser Prozess geschieht automatisch:

- Institutionsnamen: OpenAPC verwendet aus historischen Gründen keine Vorgaben für die Namen von Einrichtungen und überlässt diesen in der Regel die Schreibweise. Um trotzdem konsistente Datenhaltung zu betreiben, gibt es eine gesonderte [Tabelle](https://github.com/OpenAPC/openapc-de/blob/master/data/institutions.csv), in der Metadaten zu teilnehmenden Institutionen vorgehalten werden, hier gibt es beispielsweise auch Verweise auf Institutions-PIDs wie etwa GRID (Global Research Identifier Database) oder ROR (Research Organization Registry). Diese Tabelle wird während der Anreicherung auch zur Normalisierung verwendet, indem aus dem Verzeichnis, in dem die anzureichernde Datei liegt (`openapc_data_dir`), auf die zu verwendende Bezeichnung (`institution`) geschlossen wird.
- DOIs: Obwohl eine DOI ein persistenter Identifier ist, gibt es Unterschiede bei der Schreibweise: So ist Groß- und Kleinschreibung irrelevant, die DOI kann in Reinform, als URI (Uniform Resource Identifier) mit vorangestelltem Resolver-Link (`https://doi.org/`) oder als "Handbook"-Variante (`doi:`) dargestellt werden. OpenAPC verwendet grundsätzlich die kleingeschriebene Variante in Reinform und normalisiert alle DOIs entsprechend, hierfür gibt es eine eigene [Python-Funktion](https://github.com/OpenAPC/openapc-de/blob/v4.52.4-0-0/python/openapc_toolkit.py#L741). Dies ist beispielsweise für die Dublettenerkennung wichtig.
- Zeitschriftentitel/Verlagsnamen: Diese Metadaten werden über die DOI aus Crossref importiert, was in der Regel zu konsistenten Ansetzungen führt. Da die Crossref-Daten allerdings von den Verlagen selbst gepflegt werden, kann es auch hier gelegentlich Änderungen geben. Um solche Fälle abzufangen, gibt es zusätzliche [Mapping-Tabellen](https://github.com/OpenAPC/openapc-de/blob/v4.52.4-0-0/python/mappings.py), um abweichende Varianten zu normalisieren.

### Datenprüfung

Die Normalisierung ist erforderlich, um Inkonsistenzen in den eingereichten Daten zu beheben, allerdings müssen diese Inkonsistenzen zuvor erst einmal gefunden werden. Zu diesem Zweck werden alle Daten vor der Veröffentlichung auf GitHub automatisiert überprüft, wobei das [Pytest-Framework](https://pytest.org/) zum Einsatz kommt. Dies ist gewissermaßen eine umgekehrte Anwendung des traditionellen Software-Testings: Anstatt vordefinierte Daten zu verwenden, um veränderlichen Code zu prüfen, werden hier die geänderten Daten mittels vorgegebener Funktionen [geprüft](https://github.com/OpenAPC/openapc-de/blob/master/python/test/test_apc_csv.py). Zu den Prüfungen, die die Daten durchlaufen müssen, gehören beispielsweise:

- Syntaxprüfungen: Besteht jede Zeile aus 18 Feldern? Ist das Format der Geldbeträge korrekt, haben ISSNs und DOIs die richtige Form? Letzteres wird mittels [regulärer Ausdrücke](https://github.com/OpenAPC/openapc-de/blob/master/python/openapc_toolkit.py#L42) geprüft, bei ISSNs wird außerdem die Prüfziffer (letzte Stelle) gegengerechnet.
- Inhaltliche Prüfungen: Sind alle Pflichtfelder befüllt? Haben Felder mit Bool'schen Werten die korrekte Belegung (`TRUE` bzw. `FALSE`)? Sind innere logische Bedingungen erfüllt? Beispiel: Wenn eine Zeitschrift im DOAJ verzeichnet ist (`doaj`=`TRUE`), muss das Feld `is_hybrid` zwangsläufig `FALSE` sein, da im DOAJ grundsätzlich nur Gold-OA-Zeitschriften gelistet werden.
- Konsistenzprüfungen: Diese Tests sind am aufwändigsten, weil sie im Gegensatz zu den vorherigen Beispielen einen Eintrag auch mit allen anderen im Datensatz vergleichen. Wichtig ist hier zunächst die Dublettenprüfung (jede DOI darf nur einmal im Datensatz vorkommen) sowie Prüfungen auf konsistente Ansetzungen, die über die ISSN laufen: Haben zwei Einträge dieselbe ISSN, so sollte es sich um dieselbe Zeitschrift handeln, weshalb Verlag, Titel und Hybrid-Status ebenfalls gleich sein sollten (Ausnahmen können über spezielle [Whitelists](https://github.com/OpenAPC/openapc-de/blob/master/python/test/whitelists.py) definiert werden).

Erst wenn der Datensatz nach einer Änderung alle Tests besteht, wird er auf GitHub publiziert.

## Verbesserungspotential

Wie wir gesehen haben, ist das OpenAPC-Projekt bereits jetzt zu einem hohen Grad automatisiert und verwendet an vielen Stellen selbstgeschriebene Software, um Arbeitsabläufe zu vereinfachen und die Qualität der Ergebnisse abzusichern. Dennoch gibt es immer noch viel Raum für Optimierungen, dies betrifft insbesondere Bereiche, die nicht direkt mit der Datenverarbeitung zusammenhängen. Auf der GitHub-Seite von OpenAPC gibt es beispielsweise eine [README-Datei](https://github.com/OpenAPC/openapc-de#readme), die viele Informationen zum Projekt bereitstellt. Diese Übersicht wird regelmäßig aus einer [R Markdown-Vorlage](https://github.com/OpenAPC/openapc-de/blob/master/README.Rmd) generiert, wodurch sie sich dynamisch an die geänderte Datenlage anpasst und passende Grafiken und Tabellen selbst generiert. Dieser Ansatz ist sehr praktisch, stößt allerdings an seine Grenzen, wenn es um die Darstellung der [teilnehmenden Institutionen](https://github.com/OpenAPC/openapc-de/blob/master/README.Rmd#L63) geht. Diese sind zur Zeit in der Vorlage hartkodiert, was angesichts der mittlerweile großen Anzahl an Teilnehmern nicht mehr gut skaliert. Besonders unschön ist zudem, dass hier doppelte Datenhaltung betrieben wird, denn mit der bereits erwähnten [Institutionen-Tabelle](https://github.com/OpenAPC/openapc-de/blob/master/data/institutions.csv) gibt es bereits eine zentrale Auflistung aller Einrichtungen - hier wäre es definitiv sinnvoll, die Namen der Institutionen über eingebetteten R-Code direkt aus der Tabelle auszulesen. Als zusätzliches Metadatum müsste in diesem Fall allerdings noch eine URL mit in die Tabelle aufgenommen werden: Bei vielen Einrichtungen wird auf eine interne Seite verlinkt, die etwa Informationen zur Open Access-Policy oder einem Publikationsfonds enthält, dieser Link müsste entsprechend ebenfalls ausgelagert werden. Dies eröffnet aber wiederum Möglichkejten, um ein weiteres Problem anzugehen: Die verzeichneten URLs unterliegen dem Phänomen des "[Link Rot](https://en.wikipedia.org/wiki/Link_rot)", wodurch sich mit der Zeit tote Verweise in der Liste ansammeln. Bislang bestanden die üblichen Gegenmaßnahmen in einem gelegentlichen manuellen Abrufen sämtlicher Links sowie händischer Kontrolle und [Korrektur](https://github.com/OpenAPC/openapc-de/commit/bfd07b885b1d21e505c6813b346253e11e8bda34) - eine ungeliebte Tätigkeit, die häufig vergessen wird und tote Links zu lange stehen lässt. Hätte man die Links jedoch an zentraler Stelle und in strukturierter Form gesammelt, so wäre es ohne Weiteres möglich, sie in regelmäßigen Abständen automatisiert zu prüfen und nach dem entsprechenden [HTTP-Status](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404) Ausschau zu halten - Korrekturen müssten zwar immer noch von Hand vorgenommen werden, aber durch die kurzen Testintervalle würde sich die Arbeit entzerren und die Qualität der Daten wäre dauerhaft besser. Voraussetzung dafür wäre aber wiederum eine andere Optimierung, die bislang noch aussteht: Die Institutionen-Tabelle ist zur Zeit noch nicht in das Test-Framework eingebunden und ihre Inhalte werden daher - im Gegensatz zum OpenAPC-Datensatz selbst - nicht programmatisch geprüft. Ansätze gibt es hierfür jedoch reichlich: Neben dem bereits erwähnten möglichen Prüfen von institutionellen Linkzielen könnten etwa die persistenten Identifier GRID-ID und ROR-ID syntaktisch geprüft werden (die ROR-ID ist selbst eine URL, hier kann also zusätzlich ebenfalls ein Aufruf-Test vorgenommen werden). Der Institutions-Bezeichner könnte wechselseitig mit dem Datensatz dahingehend geprüft werden, ob alle Bezeichner im Datensatz vorhanden sind bzw. ob alle Bezeichner im Datensatz auch in der Institutionen-Tabelle vorkommen. Zuletzt könnte noch beim Inhalt des Feldes `openapc_data_dir` getestet werden, ob der angegebene Dateipfad tatsächlich existiert.

## Literatur

[^1]: Pieper, D., & Broschinski, C. (2018). OpenAPC: a contribution to a transparent and reproducible monitoring of fee-based open access publishing across institutions and nations. Insights the UKSG journal, 31. doi:10.1629/uksg.439
